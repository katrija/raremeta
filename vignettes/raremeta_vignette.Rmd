---
title: "raremeta_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{raremeta_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
library(devtools) 
load_all() 
```




<!-- # Abstract -->
<!-- This article gives an introduction to the `R`-software package -->
<!-- **raremeta**. We aim to motivate and explain the use of the package in -->
<!-- the context of conducting meta-analysis of binary data of rare events. -->
<!-- Special interest is put into variants of a common way to incorporate -->
<!-- studies with no events: *Continuity Corrections*. -->


# Introduction

In this vignette, we provide an introduction on how to fit models for meta-analysis of rare events with the R-package `raremeta`. 

The `raremeta` package contains functions for fitting several alternative models that have been proposed for meta-analysis of rare events, in particular

- the inverse-variance model with different types of continuity corrections (e.g., those proposed by Sweeting et al., 2004) and different types of estimators for the between-study variance (e.g., the improved Paule-Mandel estimator proposed by Bhaumik et al, 2012)
- the Mantel-Haenszel method (Mantel \& Haenszel, 1959) and the Peto method (Yusuf et al., 1985)
- the beta-binomial model (Kuss, 2015)
- generalized linear mixed models (GLMMs): unconditional GLMMs with fixed, study-specific intercepts or a random intercept (BÃ¶hning et al., 2015; Jackson et al, 2017) and conditional GLMMs such as the hypergeometric-normal (van Houwelingen et al. 1993) and the conditional-binomial model (Stijnen et al., 2010)

Additionally, the package contains several functions for pre-processing meta-analytic data.

The models implemented in the `raremeta` package are suitable for meta-analysis of 2x2 contingency tables, in particular when the event that is investigated is rare. 
An example for such data is provided in a meta-analysis by Hoppen et al. (2023). In this meta-analysis, the authors evaluate the efficacy and acceptability of different treatments for posttraumatic stress disorder (PTSD) in adults using network and pairwise meta-analysis.
Here, we focus on the pairwise comparison of Eye Movement Desensitization and Reprocessing (EMDR) and passive control groups with respect to the acceptability of the intervention. Acceptability is examined by investigating whether EMDR is associated with a larger (or smaller) number of dropouts compared to control treatments. A larger number of dropouts in EMDR indicates a lower acceptability of this treatment.  

The data can be reviewed by executing

```{r, eval=TRUE}
library(raremeta)
data("dat.hoppen2023")
dat.hoppen2023
```

The data frame consists of 7 rows and 5 columns. 
Each row contains one individual study. The first column, `study`, includes the study identifier, while the other columns, `ai, ci, n1i, n2i`, include information on the event counts and number of participants in the different studies. 

This information is usually depicted in form of a 2x2 contingency table,  

::: center
   $i$'th study   event   no-event  total
  -------------- ------- ---------- ----------
    treatment     $a_i$    $b_i$     $n_{1i}$
     control      $c_i$    $d_i$     $n_{2i}$
:::

where $a_i$ and $c_i$ are the numbers of events (here: dropout) in the treatment and control group of the $i-$th study, respectively, and $n_{1i}$, $n_{2i}$ are the sample sizes of these groups. The meta-analysis by Hoppen et al. is in fact an example for a meta-analysis of a rare event: Specifically, it contains one study with no event in one of the groups (single-zero study) and one study with no event in both groups (double-zero study).  

To exemplify the usage of the `raremeta` package, we apply the  the inverse-variance method for the log odds ratio with the standard continuity correction (add 0.5 to all cells of all studies with zero counts) to the data:  

```{r, eval = TRUE}
fitIV <- rareIV(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
                measure="logOR",method="FE",cc="constant",ccval=0.5,ccto="only0")

fitIV
```

Readers who are already familiar with other `R`-packages for meta analysis might recognize parts of the input syntax and the structure of the output. In the following sections, these aspects will be explained in more detail for the different functions which are part of the `raremeta`  package.

The `raremeta` package contains several functions for fitting models for rare events meta-analysis:

Function Name     | Short Description
:-------------    | :-----------------
`rareIV()`        | meta-analysis using the inverse-variance method
`rareMH()`        | meta-analysis using the Mantel-Haenszel method  
`rarePeto()`      | meta-analysis using Peto's method
`rareBetabin()`   | meta-analysis using the beta-binomial model 
`rareGLMM()`      | meta-analysis using the generalized linear mixed model  


The application of these functions is explained in detail in the following sections.

In addition, the package includes three functions for pre-processing of meta-analytic data, in particular:

Function Name     | Short Description
:-------------    | :-----------------
`rareDescribe()`  | pre-processing of a data-frame
`rareCC()`        | continuity correction for binary data
`rareES()`        | effect size estimation   


An explanation of the purpose and usage of these functions is given further below.

# Models for meta-analysis of rare events

## rareIV: meta-analysis using the inverse-variance model

The `rareIV` function allows the user to conduct a meta-analysis using the inverse-variance model.  

```{r, eval=FALSE}
rareIV(x,ai,bi,ci,di,n1i,n2i,data,measure,method,cc="none",ccval=0.5,tccval,cccval,ccsum=1,ccto="only0",
       drop00=TRUE,weighted=TRUE,weights,level=95,test="z",digits=4,verbose=FALSE,control,...)
```
The data input may be achieved in several ways.
In line with other packages for meta-analysis such as **metafor** or **meta**, the reader may specify the data frame and the columns which include the cells of the 2x2 contingency table. 
This may be done in `raremeta` by specifying the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`. We will go into more depth on the possibility to specifying the `x` argument when explaining how to pre-process the data by using the `rareDescribe` function further below.

The argument `measure` specifies the effect size or outcome measure to be used (either `"logOR"` for the log odds ratio, `"logRR"` for the log relative risk, or `"RD"` for the risk difference).

The argument `method` specifies whether a fixed- or a random-effects model should be fitted. A fixed-effects model is fitted when using `method = "FE"` . 
A random-effects model is fitted by setting method equal to one of the following: `"DL", "HE", "SJ", "ML", "REML", "EB", "HS", "PM", "IPM", "GENQ", "PMM"` or `"GENQM"`, which specifies the type of between-study variance estimator to be used.

The arguments `cc` to `ccto` define the type of continuity correction applied to the data before. Specifically, `cc` describes the type of continuity correction to be used, and can be set to `"constant"` (application of a constant continuity correction which adds the same value to all cells of the contingency table), `"tacc"` (application of a continuity correction for which the value added to the cells of the contingency table depends on the sample size ratio of the study), or `"empirical"` (application of a continuity correction for which the value is based on the pooled effect size obtained from non-zero studies). See Sweeting et al. (2004), for a description of the "tacc" and the empirical continuity correction. The argument `ccto` can be used to specify to which studies the continuity correction shall be added, and can either be set to `"all"` (apply continuity correction to all studies), `"only0"` (apply continuity correction only to zero-studies), `"if0all"` (apply continuity correction to all studies if the data frame contains any zero-study) or `"none"`.
The argument `drop00` specifies whether double-zero studies shall be excluded from the analysis, and can be set to `TRUE` or `FALSE`. The arguments `ccval`, `cccval` and `tccval` allow for a flexible specification of alternative continuity corrections defined by the user, see `?rareIV` for more details.

The `rareIV` function allows for the specification of several additional arguments. These are explained in detail in the function documentation (`?rareIV`).

We now show how to conduct a random effects meta-analysis using the inverse-variance model for the log odds ratio with the improved Paule-Mandel estimator for the between-study variance (Bhaumik et al., 2012). In line with the approach described by Bhaumik et al., we add a constant value of 0.5 to all cells of all studies.

```{r, eval=TRUE}
fitIV <- rareIV(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
                measure="logOR",method="IPM",cc="constant",ccval=0.5,ccto="all")
fitIV
```

The output begins with a short description of the type of model used, 
the numbers of studies which were part of the analysis, the type of continuity correction used and whether double-zero studies were exclueded.
In this case, the total number of studies in the Hoppen data is 7, while 6 studies were part of the analysis.
This stems from the fact, that, by default, the argument `drop00` was set to `TRUE`, which implies that double-zero studies are excluded from the analysis.  
The next part of the output reports the $Q$-statistic along with its $p$-value, heterogeneity estimate and $I^2$-statistic.

The output ends with information on the estimated pooled effect size. For the given example, we obtain a pooled log odds ratio of $0.5847$, indicating dropout is somewhat larger in the EMDR group. 

The odds ratio implied by the analysis can be obtained by executing

```{r, eval = TRUE}
exp(fitIV$beta)
```

indicating that on average the odds of dropout are about $1.79$ times as large in EMDR groups as compared to passive control groups.

The standard error associated with the pooled log odds ratio is estimated at $0.5649$. The Wald test for which the test statistic and the $p$-value are reported ($z = 1.0351$, $p = .3006$) indicates that the treatment effect is not significantly different from zero. This information can also be obtained from the confidence interval $(-0.5225, 1.6920)$, which overlaps $0$. 

## rareMH: meta-analysis using the Mantel-Haenszel method

A prominent class of estimators for the common effect size under the fixed-effects model was proposed by Mantel and Haenszel in 1959.
The `rareMH` function enables the user to conduct a meta-analysis using these types of estimators.

```{r, eval=FALSE}
rareMH(x,ai,bi,ci,di,n1i,n2i,data,measure,
       cc="constant",ccval=0.5, tccval,cccval,ccsum=1,ccto="only0",
       method="FE", level=95,digits=4,correct=FALSE, ...)
```

Data input and argument interpretation work in the same way as for the `rareIV` function (see above), for instance by specifying the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`.

The additional argument `correct` allows the user to decide whether continuity correction shall be applied. Note that there is a difference between setting the options `correct=FALSE` and `cc="none"`: While setting `correct=FALSE` implies no change of the data before estimation whatsoever, the option `cc="none"` excludes all single- (and double-) zero studies from the analysis. 
Note that when using the Mantel-Haenszel method, continuity corrections are only necessary if all studies report a zero in one of the groups, as this is the only situation in which an estimate of the pooled effect size cannot be obtained without a continuity correction.
Even though we do not fit an inverse-variance meta-analysis here, it is possible to specify the `method` argument.
This stems from the fact that we can opt for the `empirical` continuity correction, which does fit an inverse-variance meta-analysis in the process of calculating the value to be added to the specified studies. 

We now apply the `rareMH` function to our data set. 
We aim to estimate the pooled log relative risk without applying any continuity correction.

```{r,eval=TRUE}
fitMH <- rareMH(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
       measure="logRR",correct=FALSE)
fitMH
```

The output begins with a short description of the method applied and continues with the number of studies which were part of the analysis.

Then, the model results are given, i.e., the estimated log relative risk, standard error, z-val, p-val and lower- and upper bound of the confidence interval.

The estimated relative risk amounts to 
```{r, eval=TRUE}
exp(fitMH$b)
```
which indicates that on average the risk of dropout is about $1.44$ times as large in EMDR groups as compared to passive control groups.

The standard error associated with the pooled log relative risk is estimated at $0.1942$. The Wald test indicates that the treatment effect is not significantly different from zero ($z = 1.8740$, $p = .0609$). The confidence interval for the pooled log relative risk is given by $(-0.0167, 0.7447)$.

## rarePeto: meta-analysis using Peto's method

To conduct a meta-analysis on the log odds ratio using Peto's method (see Yusuf et al., 1985), the `rarePeto` function can be used.  

```{r, eval=FALSE}
rarePeto(x,ai,bi,ci,di,n1i,n2i,data,level=95,digits=4)
```

Just like for the `rareIV` and the `rareMH` function, the data input can be achieved by specifying the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`.

Peto's method allows for estimation of the pooled log odds ratio without the use of any continuity correction, even in the presence of single- and double-zero studies.  

We now apply the `rarePeto` function to our data set:

```{r, eval=TRUE}
fitPeto <- rarePeto(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023)
fitPeto
```

The output shows a short description of the model which has been fitted, the number of studies and the model results.  

The estimated odds ratio amounts to 
```{r, eval=TRUE}
exp(fitPeto$b)
```
which indicates that on average the odds of dropout are about $1.58$ times as large in EMDR groups as compared to passive control groups.

The standard error associated with the pooled log odds ratio is estimated at $0.2386$. The Wald test indicates that the treatment effect is not significantly different from zero ($z = 1.9092$, $p = .0562$). The confidence interval for the pooled effect is $(-0.0121, 0.9233)$.

## rareBetabin: meta-analysis using the beta-binomial model

The beta-binomial model, which has been proposed for meta-analysis of rare events by Kuss (2015), can be fitted using the function `rareBetabin`:

```{r, eval=FALSE}
rareBetabin(x, ai, bi, ci, di, n1i, n2i, data, measure,
  common_rho = TRUE, drop00 = FALSE, level = 95, test = "z", digits = 4,
  verbose = FALSE, control, ...)
```

Data input can be achieved for instance by specifying the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`.

The `measure` argument specifies which effect size shall be estimated. Currently, the function only allows for `measure = "logOR"` or `measure = "logRR"`. Methods for the risk difference may be added in future versions of this package.

For the example, a meta-analysis using the beta-binomial model for the log odds ratio can be obtained using the following code:

```{r}
rareBetabin(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
            measure = "logOR")
```

This fits a beta-binomial model with a common intraclass correlation (cf. Mathes & Kuss, 2021). The output shows the number of studies which the estimation was based on, the estimate of the intraclass correlation `rho`, and a summary of the model results including the estimates of the intercept and the pooled log odds ratio, their standard errors, their $z$-values and the associated $p$-values as well as the 95 \% confidence intervals. For the data by Hoppen et al. (2023), the pooled log odds ratio is estimated to be $0.6229$. The Wald-test indicates that it is not significantly different from zero ($z = 1.6645$, $p = .0960$), and the confidence interval is $(-0.1106, 1.3563)$.

It is also possible to fit a model where the intraclass correlation is allowed to be different for control vs. treatment groups. This can be achieved by setting `common_rho = FALSE`:

```{r}
rareBetabin(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
            measure = "logOR", common_rho = FALSE)
```

Here, we see that the intraclass correlation estimated for group 1  (the treatment group) is considerably larger than the intraclass correlation estimated for group 2 (the control group). Specifically, for the control group, the intraclass correlation is estimated to be $0$.

## rareGLMM: meta-analysis using the generalized linear mixed model

The `rareGLMM` function allows for fitting several different types of generalized linear mixed models, including unconditional GLMMs with fixed, study-specific intercepts or a random intercept (BÃ¶hning et al., 2015; Jackson et al, 2017) and conditional GLMMs such as the hypergeometric-normal (van Houwelingen et al. 1993) and the conditional-binomial model (Stijnen et al., 2010). The function allows for specifying the following arguments:

```{r, eval = FALSE}
rareGLMM(x, ai, bi, ci, di, n1i, n2i, data, measure,
  intercept = "fixed", slope = "random",  cor = FALSE, coding = 1/2,
  conditional = FALSE, approx = FALSE,
  drop00 = FALSE, level = 95, test = "z", digits = 4, verbose = FALSE, control,
  ...
)
```

###### Unconditional GLMMs

An unconditional GLMM may be fitted by setting the argument `conditional` to `FALSE` (which is also the default).

For the example data by Hoppen et al. (2023), an unconditional GLMM for the log odds ratio with fixed, study-specific intercepts may be fitted using the following code:

```{r}
rareGLMM(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
         measure = "logOR", 
         intercept = "fixed", slope = "random")
```

Note that several warnings are displayed which mainly concern the computation of the variance-covariance matrix of the parameters. These warnings arise because the data contain double-zero studies. Fitting the same model excluding double-zero studies removes the warning and results only in slight changes of the model results.

```{r}
rareGLMM(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
         measure = "logOR",
         intercept = "fixed", slope = "random", drop00 = TRUE)
```

The output displays the number of studies included in the estimation (here, 6 studies were included since the double-zero study was removed). Then, information with respect to between-study heterogeneity is given: Specifically, the result of the likelihood ratio test for heterogeneity is displayed, and finally the estimate of the between-study variance $\tau^2$ as well as its square root, $\tau$ are shown. In what follows, the model results are presented, specifically, the estimates of the study-specific intercepts and the pooled log odds ratio, including their standard errors, $z$-values, $p$-values and 95 \% confidence intervals. The estimate of the pooled log odds ratio is $0.6674$ with a standard error of $0.3679$. The Wald-test is not significant ($z = 1.5744$, $p = .1154$), indicating that the pooled log odds ratio is not significantly different from zero. The confidence interval is $(-0.1419, 1.3005)$.

A model with a random intercept instead of fixed, study-specific intercepts is fitted when using the following code:

```{r}
rareGLMM(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
         measure = "logOR",
         intercept = "random", slope = "random")
```

Now, an additional variance is displayed in the heterogeneity section of the output, which is the estimated variance of the study intercepts. The estimate of the average intercept is given in the model results section.

Note that per default, the random effects are assumed to be uncorrelated. This may be changed by adding `cor = TRUE` to the arguments of the `rareGLMM` function. However, allowing for correlated random effects will often result in convergence issues in meta-analysis of rare events.

###### Conditional GLMMs

The conditional GLMM for the log odds ratio is the hypergeometric model. A random-effects version of this model, the hypergeometric-normal model (van Houwelingen et al., 1993), can be fitted using the following code:

```{r}
rareGLMM(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
         measure = "logOR", conditional = TRUE, approx = FALSE,
         intercept = "random")
```

Note that the argument `intercept = "random"` is required to obtain a random-effects model, since the hypergeometric model is an intercept-only model. Note that this model is currently implemented by internally calling the `rma.glmm` function from the `metafor` package. The output is similar to the output obtained when fitting an unconditional GLMM, but shorter since the only parameters of this model are the log odds ratio and the between-study variance. The estimate of the pooled log odds ratio for the hypergeometric-normal model is $0.6953$ with a standard error of $0.4522$ and a 95 \% confidence interval of $(-0.1910, 1.5817)$. The Wald test indicates that the pooled log odds ratio is not significantly different from $0$ ($z = 1.5376$, $p = .1242$). 

An approximate version of this model, the conditional-binomial model (Stijnen et al., 2010), can be obtained by specifying `approx = TRUE`.

```{r}
rareGLMM(ai = ai, ci = ci, n1i = n1i, n2i = n2i, data = dat.hoppen2023,
         measure = "logOR", conditional = TRUE, approx = TRUE,
         intercept = "random")
```

Compared to the exact model, we obtain a smaller estimate of the pooled log odds ratio as well as a smaller estimate of the between-study variance.

# Pre-processing meta-analytic rare event data

In the following subsection, we explain the usage of different functions allowing for pre-processing meta-analytic rare event data, specifically:

- `rareDescribe`: function for pre-processing a data frame and obtaining descriptive statistics with respect to sample sizes, numbers of events, as well as the numbers of single- and double-zero studies
- `rareCC`: function for applying continuity corrections to meta-analytic data
- `rareES`: function for calculating study-specific effect size estimates for different types of effect sizes, such as log odds ratios, log relative risks, and risk differences


## rareDescribe
Instead of data input via columns of a specified data frame, there is also the option of pre-processing the data to make it easier to handle.
This can be done by turning the data into an object of type `rareData` by using the `rareDescribe` function.
The `rareDescribe` function computes descriptive statistics of the meta-analytic data and stores them in a list object. 
This object can then be used as data input into all of the other functions.
This feature is especially useful when the user wants to use more than one `raremeta` function on the same data, e.g., when fitting several different models as a sensitivity analysis. We will now show how to produce a `rareData` object using the `rareDescribe` function:

```{r, eval=FALSE}
rareDescribe(ai, bi, ci, di, n1i, n2i, data)
```

The data input can be achieved by specifying the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`. For the data by Hoppen et al. (2023), we can use the following lines of code to 

1. Produce a `rareData` object (`x`) using `rareDescribe`.
2. Conduct a meta-analysis using the inverse-variance method with the `rareIV` function.
3. Conduct a meta-analysis using the Mantel-Haenszel method.
4. Conduct a meta-analysis using the Peto method.


```{r, eval=FALSE}
x <- rareDescribe(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023)
rareIV(x, measure="logOR",method="IPM",cc="constant",ccval=0.5,ccto="all")
rareMH(x,measure="logRR",correct=FALSE)
rarePeto(x)
```

Note that for steps 2-4, we have used the `rareData` object `x` as input instead of specifying the data input using the arguments `data, ai, n1i, ci, n2i`.

When using the `print` method on a `rareData` object, the user obtains an overview of several descriptive statistics of the meta-analytic data:

```{r, include=FALSE}
x <- rareDescribe(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023)
```

```{r}
print(x)
```

The output begins with a summary of the original data:
First, the number of studies, the number of single-zero studies and the number of double-zero studies are given, followed by descriptive statistics of the sample sizes of the treatment group (group 1) and the control group (group 2) (mean, standard deviation, minimum, 25 % quantile, median, 75 % quantile, maximum, and interquartile range). The same descriptive statistics are then given for the sample size ratio (n1i/n2i). Finally, descriptive statistics of the relative frequencies of the event in the two groups and in the whole sample are displayed.

## rareCC
The `rareCC` function enables the user to apply continuity correction to the data before fitting meta-analytic models. Although with most functions, such as `rareIV` or `rareMH`, the continuity correction can be applied internally, users may find it easier to pre-process the data using the `rareCC` function and then use the object obtained as a data input for the model functions.

We will now have a look at the arguments of the `rareCC` function:

```{r, eval=FALSE}
rareCC(x,ai,bi,ci,di,n1i,n2i,data,cc="constant",ccval=0.5,tccval,cccval,ccsum=1,
       ccto="only0",drop00=TRUE,measure,method="FE")
``` 

As always, data input can be achieved by specifying the `x` argument or the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`.

The built-in options of the `rareCC` function include three different families of continuity corrections: The *constant*, *treatment-arm*, and *empirical* continuity corrections. Beyond that, the user can flexibly specify their own continuity correction using the arguments `ccval` or `tccval` and `cccval` (see below).

###### Constant continuity correction
When setting `cc = "constant"`, a constant value will be added to all cells of all studies specified via the `ccto` argument. The default is `ccval = 0.5`. 
Through specification of `tccval` and `cccval` different values can be specified for the cells of the treatment group and the control group, respectively. 
By specifying vectors as inputs for the `tccval` and `cccval` arguments, different values can be added to different studies (adding the k-th value to the k-th study), making it possible for the user to introduce their own continuity correction.

###### Treatment-arm continuity correction
When setting `cc = "tacc"` (treatment-arm continuity correction), the values of the continuity correction that are applied to the treatment and control groups are based on the ratios of their sample sizes. For a detailed description of this type of continuity correction, see Sweeting et al. (2004).

###### Empirical correction
When setting `cc = "empirical"`, the value of the continuity correction is obtained based on an estimate of the pooled effect that is obtained from the inverse-variance model excluding all zero-studies. This means that there must be at least one non-zero study providing an estimate of the study-specific effect size. For a detailed description of the empirical continuity correction, see Sweeting et al. (2004).

Since the value of the empirical continuity correction depends on the effect size, it is necessary to specify the `measure` argument when using this continuity correction. Possible effect sizes are `"logOR`, `"logRR"`, and `"RD"`. The estimate of the pooled effect used to calculate the value of the continuity correction may be based on different models, i.e., on the fixed-effects model (also known as equal-effects model) or on the random-effects model. A fixed-effects model is fitted when `method` is set to `"FE"` (or `"EE"`). A random-effects model is fitted when `method` is set to either `"DL", "HE", "SJ", "ML", "REML", "EB", "HS", "PM", "IPM", "GENQ", "PMM"` or `"GENQM"`, which also specifies the type of between-study variance estimator to be used. 
Currently, the model is fitted by applying the `rma()` function from the **metafor** package, see Viechtbauer (2010).  

<!-- As always, `drop00` is a logical, indicating whether double-zero studies shall be dropped from the analysis.   -->
<!-- The argument `ccto` is a character string indicating which studies the continuity correction should be applied to. Either `"only0"`, for which the continuity correction is applied to all studies for which the number of events is zero in at least one of the groups, `"all"`, for which the continuity correction is applied to all studies, or `"if0all"`, for which the continuity correction is applied to all studies if any of the individual studies has zero events in at least one of the groups.   -->

We will now show how to use the `rareCC` function using the data by Hoppen et al. (2023) as an example.  

We begin with the constant continuity correction and add $0.5$ to all cells of all studies with zero events in one of the groups.

```{r, eval=TRUE}
x <- rareCC(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
            cc="constant",ccval=0.5,ccto="only0", drop00=TRUE)

data.frame(x$ai.cc,x$ci.cc,x$n1i.cc,x$n2i.cc)
data.frame(x$ai,x$ci,x$n1i,x$n2i)

```

As the output above shows, it is possible to obtain the values of the cells of the continuity-corrected data by calling `x$ai.cc`, `x$ci.cc`, `x$n1i.cc` and `x$n2i.cc`. For comparison, we also show the values of the cells of the original data. Since we excluded double-zero studies by specifying `drop00=TRUE`, the double-zero study. The continuity correction was only applied to the single-zero study, as specified by `ccto = "only0"`.

If we want apply the `empirical` continuity correction to all studies, not excluding the double-zero studies, we call:

```{r, eval=TRUE}
x <- rareCC(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
            cc="empirical",measure="logOR",method="FE",ccto="all",drop=FALSE)

round(data.frame(x$ai.cc,x$ci.cc,x$n1i.cc,x$n2i.cc),2)
data.frame(x$ai,x$ci,x$n1i,x$n2i)

```

The object `x` which is produced by the `rareCC` function is a `rareData` object, which can be used as a data input for other functions, such as for the `rareIV` function:

```{r, eval=TRUE}
rareIV(x, measure = "logOR", method = "IPM")
```

The model functions are set up in such a way that a data set to which a continuity correction has already been applied using the `rareCC` function will not be corrected again. Therefore, the user must not fear applying a continuity correction twice when using this approach.

## rareES
To calculate study-specific effect sizes for meta-analysis of rare events, the `rareES` function can be used. 

```{r, eval=FALSE}
rareES(x,ai,bi,ci,di,n1i,n2i,data,measure,
       cc="constant",ccval=0.5,tccval,cccval,ccsum=1,
       ccto="only0",drop00=TRUE,method="FE")
```

Data input can be achieved by specifying the `x` argument or the arguments `data, ai, bi, ci, di` or `data, ai, n1i, ci, n2i`. 

The argument `measure` specifies the effect size or outcome measure to be used (either `"logOR"` for the log odds ratio, `"logRR"` for the log relative risk, or `"RD"` for the risk difference). 

The arguments from `cc` to `ccto` and `method` specify the continuity correction to be applied before calculation of the effect size estimate. Note that the `method` argument is only required when specifying `cc = "empirical"`. For this type of continuity correction, the `method` argument specifies the model used in the calculation of the values for the continuity corrections (see above). The argument `drop00` is a  logical indicating whether double-zero studies should be excluded prior to calculating the study-specific effect sizes and sampling variances.    

We will now show how to use the `rareES` function. 
We calculate the log odds ratio on the study level for the Hoppen data set. 

```{r, eval=TRUE}
x <- rareES(ai=ai,ci=ci,n1i=n1i,n2i=n2i,data=dat.hoppen2023,
            measure="logOR")
```

The `rareES` function turned the Hoppen data into an object of type `rareData`, adding the information about the estimated effect size and the sampling variances.

The estimates of the study-specific effect sizes and their sampling variances can be obtained by calling `x$yi` and `x$vi`, respectively:

```{r, eval=TRUE}
x$yi
x$vi
```


## References

Bhaumik, D. K., Amatya, A., Normand, S.-L. T., Greenhouse, J., Kaizar, E., Neelon, B., & Gibbons, R. D. (2012). Meta-Analysis of Rare Binary Adverse Event Data. Journal of the American Statistical Association, 107 (498), 555â567. doi: 10.1080/01621459.2012.664484

BÃ¶hning, D., Mylona, K., & Kimber, A. (2015). Meta-analysis of clinical trials with rare events. Biometrical Journal, 57 (4), 633â648. doi: 10.1002/bimj.201400184

Hoppen, T. H., Jehn, M., Holling, H., Mutz, J., Kip, A., & Morina, N. (2023). The efficacy and acceptability of psychological interventions for adult PTSD: A network and pairwise meta-analysis of randomized controlled trials. Journal of Consulting and Clinical Psychology. doi: 10.1037/ccp0000809

Jackson, D., Law, M., Stijnen, T., Viechtbauer, W., & White, I. R. (2018). A comparison of seven random-effects models for meta-analyses that estimate the summary odds ratio. Statistics in Medicine, 37 (7), 1059â1085. doi: 10.1002/sim.7588

Kuss, O. (2015). Statistical methods for meta-analyses including information from studies without any eventsâadd nothing to nothing and succeed nevertheless. Statistics in Medicine, 34 (7), 1097â1116. doi: 10.1002/sim.6383

Mantel, N., & Haenszel, W. (1959). Statistical Aspects of the Analysis of Data From Retrospective Studies of Disease. JNCI: Journal of the National Cancer Institute. doi: 10.1093/jnci/22.4.719

Mathes, T., & Kuss, O. (2021). Beta-binomial models for meta-analysis with binary outcomes: Variations, extensions, and additional insights from econometrics. Research Methods in Medicine & Health Sciences, 2(2), 82-89. doi: 10.1177/2632084321996225

Stijnen, T., Hamza, T. H., & Ãzdemir, P. (2010). Random effects meta-analysis of event outcome in the framework of the generalized linear mixed model with applications in sparse data. Statistics in Medicine, 29 (29), 3046â3067. doi: 10.1002/sim.4040

Sweeting, M. J., Sutton, A. J., & Lambert, P. C. (2004). What to add to nothing? Use and avoidance of continuity corrections in meta-analysis of sparse data. Statistics in Medicine, 23 (9), 1351â1375. doi: 10.1002/sim.1761

van Houwelingen, H. C., Zwinderman, K. H., & Stijnen, T. (1993). A bivariate approach to meta-analysis. Statistics in Medicine, 12 (24), 2273â2284. doi: 10.1002/sim.4780122405

Yusuf, S., Peto, R., Lewis, J., Collins, R., & Sleight, P. (1985). Beta blockade during and after myocardial infarction: an overview of the randomized trials. Progress in Cardiovascular Diseases, 27 (5), 335â371. doi: 10.1016/s0033-0620(85)80003-7
